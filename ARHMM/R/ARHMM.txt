
# Author: Ali Rafei, 2012 
# E-mail: a-rafei {AT} alumnus {DOT} tums {DOT} ac {DOT} ir 
# A package written in R to apply a modify Autoregressive Hidden Markov Model


#############################################################################
#                      LIKELIHOOD CALCULATION                    
#############################################################################

llf <- function(Y, theta, ar = 0, r = 12){
	Y2 <- Y
	Y <- Y[-c(1:ar)]
	m <- ncol(theta)
	n <- length(Y)

	# construct autoregressive covariates
	Yt <- c()
	if(ar>0){
		for(i in 1:ar){
			Yt <- cbind(Yt, c(rep(NA, i), Y2[1:(n+ar-i)]))
		}
	}
	Yt <- Yt[-c(1:ar), ]
	
	# Model trend and seasonality, densities can be normal or exponential
	f <- c()
	for(i in 1:m){
		ts.flag <- theta[2, i]
		if (theta[1, i] == 0){
			# Normal density
			if (ts.flag == 1){
				# with trend/seasonality modeling
				# calculate time dependent means
				js <- 1:n
				w <- cbind(rep(1,n), js, cos((2*pi/r)*js), sin((2*pi/r)*js), Yt)
				mu <- as.vector(w%*%theta[3:(6+ar),i])     
				sigma <- sqrt(theta[7+ar,i])
				# compute likelihood of observarion sequence
				llh <- dnorm(Y, mu, sigma)
			} else{
				# no trend/seasonality modeling
				llh <- dnorm(Y, theta[3,i], sqrt(theta[4,i]))
			}
		}
    
		if(theta[1, i] == 1){
		# Exponential density
			if(ts.flag == 1){
				# with trend/seasonality modeling
				# calculate time dependent means 
				js <- 1:n
				w <- cbind(rep(1, n),js,cos((2*pi/r)*js),sin((2*pi/r)*js),Yt)
				lambda <- as.vector(w%*%theta[3:(6+ar),i])
				# compute likelihood of observation sequence
				llh <- dexp(Y, lambda)
			} else{
				# no trend/seasonality modeling      
				lambda <- theta[3,i]
				llh <- dexp(Y, lambda)
			}
		}    

		if (theta[1,i] == 2){
			# Log-Normal density
			if (ts.flag==1){
				# with trend/seasonality modeling
				# calculate time dependent means      
				js <- 1:n
				w <- cbind(rep(1,n),js,cos((2*pi/r)*js),sin((2*pi/r)*js),Yt)
				mu <- as.vector(w%*%theta[3:(6+ar),i])
				sigma <- sqrt(theta[7+ar,i])
				# compute likelihood of observation sequence
				llh <- dlnorm(Y, mu, log(sigma))
			} else{  
					# no trend/seasonality modeling
					llh <- dlnorm(Y, theta[3,i], log(sqrt(theta[4,i])))
			}
		}

		if (theta[1,i] == 3){
			# Poisson density
			if (ts.flag==1){
			# with trend/seasonality modeling
			# calculate time dependent means
			js <- 1:n
			w <- cbind(rep(1,n),js,cos((2*pi/r)*js),sin((2*pi/r)*js),Yt)
			lambda <- as.vector(w%*%theta[3:8,i])
			# compute likelihood of observation sequence
			llh <- dpois(Y, lambda)
			} else{
				# no trend/seasonality modeling
				js <- 1:n
				w <- cbind(rep(1,n),js,cos((2*pi/r)*js),sin((2*pi/r)*js),Yt)
				lambda1 <- as.vector(w%*%theta[3:(6+ar),i-1])      
				lambda <- theta[3,i]*rep(1,n)+lambda1
				llh <- dpois(Y, lambda)
			}
		}

		# add another row to the likelihood matrix (i.e. likelihood of 
		# observing data points in state i)

		f <- rbind(f, llh)
	}
	return(f)
}

#############################################################################
#                      FORWARD BACKWARD METHOD                    
#############################################################################

forward.backward <- function(f, T, P){

	m <- dim(T)[1]
	n <- dim(f)[2]

	scale <- 1

	a <- matrix(0,m,n)
	b <- matrix(0,m,n)
	r <- rep(0,n)
 
	# forward part (a)
	# initialization
	a[,1] <- P*f[,1]
	if (scale==1) {
		r[1] <- ceiling(log10(sum(a[,1],na.rm=T)))
		a[,1] <- a[,1]/10^r[1]
	}
	# induction
	for(j in 1:(n-1)){
		for(i in 1:m){
			a[i,j+1] <- 0
			for(h in 1:m){
				a[i,j+1] <- a[i,j+1]+a[h,j]*T[h,i]
			}
			a[i,j+1] <- a[i,j+1]*f[i,j+1]
		}
		r[j+1] <- ceiling(log10(sum(a[,j+1],na.rm=T)))
		if (scale==1){
			a[,j+1] <- a[,j+1]/10^r[j+1]
		}
	}
	sf <- 0
	for(j in 1:n){
		sf <- sf+r[j]
	}

	# termination (likelihood)
	L <- sf*log(10) + log(sum(a[,n],na.rm=T))
 
	# backward part (b)
	# initialization
	b[,n] <- rep(1,m)
	r[n] <- ceiling(log10(sum(b[,n],na.rm=T)))
	b[,n] <- b[,n]/10^r[n]
	# induction
	for(j in (n-1):1){
		for(h in 1:m){
			b[h,j] <- 0
			for(i in 1:m){
				b[h,j] <- b[h,j]+T[h,i]*f[i,j+1]*b[i,j+1]
			}
		}
		r[j] <- ceiling(log10(sum(b[,j],na.rm=T)))
		b[,j] <- b[,j]/10^r[j]
	}
	return(list(a=a,b=b,L=L))
}

#############################################################################
#                      TRAIN HIDDEN MARKOV MODEL                   
#############################################################################

train.hmm <- function(Y, T, P, theta, r=12, conv.thresh = 10^-5, maxit = 10000){
	# global r mpass npass Ypass tau2;
	# remember initial density parameters
	initial.theta <- theta

	Y1 <- Y
	Y <- Y[-c(1:ar)]
 
	# extract input sizes
	n <- length(Y)
	m <- ncol(T)

	# extract max # of params
	maxparams <- nrow(theta)
 
	# define variables
	tau3 <- array(0,c(m,m,n-1))
	tau2 <- matrix(0,m,n)
 
	logL <- c()
	oldL <- -Inf
	num.it <- 0
	converged <- FALSE
	while ((num.it < maxit) & !converged){
		#
		# E step
		#
 
		# precalculate conditional likelihood values
		f <- density(Y1, theta, r)
  
		# run forward-backward to compute a and b
		a <- forward.backward(f, T, P)$a         # tt = [a, b, newL] 
		b <- forward.backward(f, T, P)$b 
		newL <- forward.backward(f, T, P)$L 
		logL <- c(logL, newL)
 
		# calculate tau_{hij}
		for (j in 1:(n-1)){
			for (h in 1:m){
				for (i in 1:m){
					tau3[h,i,j] <- a[h,j]*T[h,i]*f[i,j+1]*b[i,j+1]
				}
			}
    
			tauslice <- tau3[,,j]
			normf <- sum(tauslice,na.rm=T)
			tau3[,,j] <- tau3[,,j]/normf
		}
 
		# calculate tau_{i1}
		for(i in 1:m){
			tau2[i,1] <- P[i]*f[i,1]
		}
		normf=sum(tau2[,1],na.rm=T)
		if (normf !=0) {
			tau2[,1] <- tau2[,1]/normf
		} else{
				warning("normalization factor is zero")
		}

		# calculate tau_{ij}
		for(i in 1:m){
			for(j in 2:n){
				tau2[i,j] <- sum(tau3[,i,j-1],na.rm=T)
			}
		}
 
		#
		# M step
		#
  
		# update priors
		P <- tau2[,1]
  
		# update transition probabilities
		for(h in 1:m){
			for(i in 1:m){
				# T[h,i]=sum(tau3[h,i,],na.rm=T)/sum(tau2[h,1:n-1],na.rm=T)
				T[h,i] <- 0
				s <- 0
				for(j in 1:(n-1)){
					T[h,i] <- T[h,i] + tau3[h,i,j]
					s <- s + tau2[h,j]
				}
				T[h,i] <- T[h,i]/s
			}
		}
  
		# normalize T
		for(h in 1:m){
			T[h,] <- T[h,]/sum(T[h,],na.rm=T)
		}
  
		# update of conditional distribution parameters
  
		# remember distribution types and trend/seasonality flag
		distr.type <- theta[1,]
		ts.flag <- theta[2,]
		################################################################## 
		# update seasonality and trend parameters of all states
		oldtheta <- theta
		theta <- c()
		mu <- matrix(0,m,n)
		for(i in 1:m){
			# what kind of density does this state have?
			if(distr.type[i]==0){
			# Normal density
				if (ts.flag[i]==1){
					# with trend/seasonality modeling
					M <- matrix(0,6,6)
					v <- rep(0,6)
					for(j in 1:n){
						w <- c(1, j, cos(2*j*pi/r), sin(2*j*pi/r), Y1[j+1], Y1[j])
						M <- M + tau2[i,j]*(w%*%t(w));
						v <- v + tau2[i,j]*Y[j]*w
					}
					param <- c(as.vector(solve(M)%*%v), 0)
    
					# update variances
					# construct means from trend/seasonality parameters
					for(j in 1:n){
						w <- c(1, j, cos(2*j*pi/r), sin(2*j*pi/r), Y1[j+1], Y1[j])
						mu[i,j] <- t(w)%*%param[-7]
					}
    
					for(j in 1:n){
						param[7]=param[7]+tau2[i,j]*(Y[j]-mu[i,j])^2
					}
					param[7] <- param[7]/sum(tau2[i,],na.rm=T) 
				} else{
					# no trend/seasonality modeling
					mu <- 0
					D <- 0
					for(j in 1:n){
						mu <- mu + tau2[i,j]*Y[j]
						D <- D + tau2[i,j]*(Y[j]^2)
					}
					normf <- sum(tau2[i,],na.rm=T)
					mu <- mu/normf
					D <- D/normf
    
					sigma2 <- D - (mu^2)
					param <- c(mu,sigma2)
					}
				}
				## 
				if(distr.type[i]==1){
					# Exponential density
					if(ts.flag[i]==1){
						# with trend/seasonality modeling
						M <- matrix(0,6,6)
						v <- rep(0,6)
							for(j in 1:n){
								w <- c(1,j,cos(2*j*pi/r),sin(2*j*pi/r), Y1[j+1], Y1[j])
								M <- M + tau2[i,j]*(w%*%t(w))
								v <- v + tau2[i,j]*Y[j]*w
							}
							param <- c(as.vector(solve(M)%*%v), 0)
   
						# update variances							
						# construct means from trend/seasonality parameters
						for(j in 1:n){
							w <- c(1,j,cos(2*j*pi/r),sin(2*j*pi/r), Y1[j+1], Y1[j])
							mu[i,j] <- as.vector(t(w)%*%param[-7])
						} 
					} else{
						# without trend/seasonality modeling
							param <- (tau2[i,]%*%Y)/sum(tau2[i,],na.rm=T)
					}
				}

					## 
					if(distr.type[i]==2){
						# lognormal density
						if (ts.flag[i]==1){
							# with trend/seasonality modeling
							M <- matrix(0,6,6)
							v <- rep(0,6)
							for(j in 1:n){
								w <- c(1,j,cos(2*j*pi/r*j),sin(2*j*pi/r), Y1[j+1], Y1[j])
								M <- M + tau2[i,j]*(w%*%t(w));
								v <- v + tau2[i,j]*Y[j]*w
							}
							param <- (tau2[i,]%*%Y)/sum(tau2[i,],na.rm=T)
    
							# update variances
							# construct means from trend/seasonality parameters
							for(j in 1:n){
								w <- c(1,j,cos(2*j*pi/r),sin(2*j*pi/r), Y1[j+1], Y1[j])
								mu[i,j] <- (t(w)%*%param[-7])
							}
    
							for(j in 1:n){
								param[6] <- param[6,] + tau2[i,j]*(Y[j]-mu[i,j])^2
							}
						param[7] <- param[7]/sum(tau2[i,],na.rm=T)
						} else{
							# *** no trend/seasonality modeling
							#  replace zero data with .01 (avoid log(0))
							Yp <- Y
							if (any(Yp==0)){
								Yp[Yp==0] <- 0.01
							}
							param <- (tau2[i,]*log(Yp))/sum(tau2[i,],na.rm=T)
							param <- c(param,(tau2[i,]*((log(t(Yp))-param*rep(1,n))^2))/sum(tau2[i,],na.rm=T))
						}
					}

			## 
			if(distr.type[i]==3){
			# *** Poisson density
				if (ts.flag[i]==1){
					# with trend/seasonality modeling
					ti <- 1:length(Y)
					x1i <- cos(2*pi*ti/r)
					x2i <- sin(2*pi*ti/r)
					x3i <- Y1[2:(length(Y1)-1)]
					x4i <- Y1[1:(length(Y1)-2)]
					data2=data.frame(Y,ti,x1i,x2i,x3i,x4i)
					reg <- lm(Y~ti+x1i+x2i+x3i+x4i,weights=as.vector(tau2[i,]),data=data2)
					param <- reg$coefficients
					
					# update variances
					# construct means from trend/seasonality parameters
					for (j in 1:n){
						w <- c(1,j,cos(2*j*pi/r),sin(2*j*pi/r), Y1[j+1], Y1[j])
						mu[i,j] <- t(w)%*%param[-7]
					} 
				} else{
    
					# without trend/seasonality modeling
					js <- 1:n
					w <- cbind(rep(1,n),js,cos((2*pi/r)*js),sin((2*pi/r)*js),Yt)
					lambda2 <- as.vector(w%*%theta[3:8,i-1])      
					param <- (tau2[i,]%*%(Y-lambda2))/sum(tau2[i,],na.rm=T)
				}
			}
			# store updated density parameters for this state
			theta <- cbind(theta,c(distr.type[i],ts.flag[i],param,rep(0,(maxparams-length(param)-2))))
		}
 
		# check for convergence
		converged <- abs(oldL-newL) < conv.thresh
		if (newL<oldL){
			stop("WARNING: likelihood decreased!")
		}
		oldL <- newL
 
		num.it <- num.it+1
  
	}
	return(list(iteration=num.it, Initial.Probability=P, Transition.Matrix=T, log.likelihood=oldL, theta=theta))
}

#############################################################################
#                      VITERBI ALGORITHM                  
#############################################################################
viter <- function(Y, P, T, theta, r){

	Y1 <- Y
	Y <- Y[-c(-1:ar)]

	# get input sizes
	n <- length(Y)
	m <- dim(T)[2]

	# precalculate conditionals for every state/observation pair
	f <- density(Y1, theta, r)

	# initialize delta, psi
	delta <- matrix(0,m,n)
	psi <- matrix(0,m,n)
	for(i in 1:m){
		delta[i,1] <- P[i]*f[i,1]
	}

	# recursion
	for(j in 2:n){
		for(i in 1:m){
			c <- delta[,j-1]*T[,i]
			delta[i,j] <- max(c)*f[i,j]
			idx <- (1:length(c))[c >= max(c)]
			# in case we find more than one maximum value, use first one
			psi[i,j] <- idx[1]
		}
  
		# scale delta values to keep them from growing too large or too small
		scalef <- ceiling(log10(sum(delta[,j],na.rm=T)))
		delta[,j] <- delta[,j]/(10^scalef)
	}

	# backtracking
	# initialize
	S <- (1:length(delta[,n]))[delta[,n]>= max(delta[,n])]
	# break ties
	S <- S[1]

	# recurse
	for(j in n:2){
		S <- c(psi[S[1],j],S)
	}
	return(S)
}


#############################################################################
#                      PREDICTION                 
#############################################################################

	prediction <- function(y, theta, Sts, r){
	# global r T y  rates Sts theta;
	n <- length(y)
	m <- dim(theta)[2]
	yfit <- rep(0,n)

	stk <- 0

	for (i in 1:n){
		stk <- Sts[i]  #stk <- State kind
		if (theta[2,stk]==1){
			cy <- (2*pi*i)/r
			yfit[i] <- theta[3,stk]+theta[4,stk]*i+theta[5,stk]*sin(cy)+theta[6,stk]*cos(cy)
		}else{
			yfit[i] <- theta[3,stk]
		}
	}

	par(mfrow=c(2,1))
	plot(1:length(y), y, type="l", col="blue", ylim=c(min(y)-5, max(y)+5))
	plot(1:length(y), yfit, type="s", col="red", ylim=c(min(yfit)-5, max(yfit)+5))

	Error <- y-yfit
	SE <- Error^2

	SSY <- sum((y-mean(y))^2,na.rm=T)
	SSE <- sum(SE,na.rm=T)
	SSR <- SSY-SSE
	R2 <- SSR/SSY
	rr <- cor(y, yfit)

	numepi <- sum(Sts==m,na.rm=T)

	list(SSR=SSR, SSE=SSE, SSY=SSY, R.Square=R2, Number.of.Epidemic.States=numepi, cortest=cor.test(Y, yfit))
}
